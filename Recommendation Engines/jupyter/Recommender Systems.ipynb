{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems for BoardGamesGeek.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "#line-by-line runtime comparison for easier code optimization.\n",
    "%load_ext line_profiler\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "elite = pd.read_csv('../inputs/boardgame-elite-users.csv')\n",
    "elite = elite.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "titles = pd.read_csv('../inputs/boardgame-titles.csv')\n",
    "titles = titles.rename(columns={'boardgamegeek.com game ID':'gameID'})\n",
    "frequent = pd.read_csv('../inputs/boardgame-frequent-users.csv')\n",
    "frequent = frequent.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "#load up the big dataset\n",
    "#users = pd.read_csv('../inputs/boardgame-users.csv')\n",
    "#users = users.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Predictor\n",
    "This is the simplest predictor I'm making for the project. It doubles as a way to normalize the Ratings matrix R for more complex algorithms (like SVD) that require some kind of a way to fill missing ratings in the sparse matrix. Subtracting the baseline prediction from each value in R normalizes so that missing values can be set to 0.\n",
    "\n",
    "All this prediction does is use the user rating averages, total average rating, and average item ratings to come up with a believable first guess. Details are in section 2.1 of the paper linked in the exploratory notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Base_Predictor(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self, DAMPENING_TERM=25, dampening=False):\n",
    "        self._dampening_term = 25\n",
    "        self._dampening = dampening\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._mean = y.mean()\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        self._bu = self._R.apply(lambda row: self._user_base(row), axis=1)\n",
    "        self._bi = self._R.apply(lambda column: self._item_base(column))\n",
    "        \n",
    "    def _user_base(self, row):\n",
    "        \"\"\"(1/M+d)*bu is with the dampening factor. Without it's 1/M * bu. To find the way to add the \n",
    "        dampening factor as a scalar multiplication: \n",
    "            k*1/M(bu) = 1/M+d(bu)\n",
    "            k = M/M+d\"\"\"\n",
    "        bu = row.mean() - self._mean\n",
    "        if self._dampening:\n",
    "            num_items_user_reviewed = row[row.notnull()].size\n",
    "            damp_factor = num_items_user_reviewed/(num_items_user_reviewed+self._dampening_term)\n",
    "            bu*=damp_factor\n",
    "        return bu\n",
    "    \n",
    "    def _item_base(self, column):\n",
    "        users_that_reviewed_this_item = column[column.notnull()]\n",
    "        bu_for_users_that_reviewed_i = self._bu[users_that_reviewed_this_item.index].mean()\n",
    "        bi = users_that_reviewed_this_item.mean()-bu_for_users_that_reviewed_i-self._mean\n",
    "        if self._dampening:\n",
    "            num_users_reviewed_item = column[column.notnull()].size\n",
    "            damp_factor = num_users_reviewed_item/(num_users_reviewed_item+self._dampening_term)\n",
    "            bi*=damp_factor\n",
    "        return bi\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._mean + self._bu[X.UserID].values + self._bi[X.gameID].values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little Unit Testing for Sanity's sake.\n",
    "I just made a simple 3x3 test data set with one missing value. I ran through the calculations by hand, and set up a little battery of tests to make sure it all works. I print out the 3 pieces of info so you can see visually. There's TDD_test_X, the user, item pair I predict. TDD_train_X is the list of values at the bottom, the middle matrix is TDD_test_X blown up into the ratings matrix (with the missing value I'm testing for showing). As long as this cell compiles without triggering an assertion error, things are working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID\n",
       "0       3       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  5    6\n",
       "1  7  4  8.0\n",
       "2  5  7  3.0\n",
       "3  7  8  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID  rating\n",
       "0       1       4     7.0\n",
       "1       1       5     4.0\n",
       "2       1       6     8.0\n",
       "3       2       4     5.0\n",
       "4       2       5     7.0\n",
       "5       2       6     3.0\n",
       "6       3       4     7.0\n",
       "7       3       5     8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_ratings_matrix = pd.DataFrame(np.random.randint(1,10,size=(3,3)),columns=map(int,list('456')),index=map(int,list('123')))\n",
    "test_ratings_matrix.loc[3,6] = np.NaN\n",
    "#collapse test frame down the same format as our dataset. 3 columns, user\n",
    "TDD_train_X = test_ratings_matrix.stack().reset_index()\n",
    "TDD_train_X.columns = ['UserID','gameID','rating']\n",
    "TDD_test_X = pd.DataFrame(data={'UserID':[3],'gameID':[6]})\n",
    "display(TDD_test_X)\n",
    "display(test_ratings_matrix)\n",
    "display(TDD_train_X)\n",
    "\n",
    "def test_baseline_predictor():\n",
    "    predictor = Base_Predictor()\n",
    "    predictor.fit(TDD_train_X[['UserID','gameID']],TDD_train_X.rating)\n",
    "    assert predictor._mean == 6.125, \"The incorrect mean was calculated for the baseline test set\"\n",
    "    assert predictor._bu.tolist() == [0.20833333333333304,-1.125,1.375], \"The wrong bu values were calculated for the baseline test\"\n",
    "    assert predictor._bi.tolist() == [0.05555555555555536, 0.05555555555555536, -0.16666666666666607], \"incorrect bi was calculated for baseline test\"\n",
    "    assert predictor.predict(TDD_test_X).tolist() == [7.333333333333334], \"baseline prediction for the test value was incorrect\"\n",
    "        \n",
    "\n",
    "test_baseline_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Collaborative Filtering\n",
    "\n",
    "This is the system described in section 2.2 of the linked paper. The idea is that to predict the rating of user U and item I, you use the normalized average rating of the N most similar users to U who have reviewed item I. There are multiple similarity measures that can be used, and several other hyper paramters that can be tweaked that can be fed into the class constructor for testing and comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class U_U_predictor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    #ratings matrix from the actual training values\n",
    "    #_R \n",
    "    \n",
    "    #precomputing user's average ratings and std to save time later.\n",
    "    #_user_average_rating\n",
    "    #_user_standard_deviation\n",
    "    \n",
    "    #user similarity matrix (size user x user)\n",
    "    #_S\n",
    "    \n",
    "    #function that changes depending on selected similarity metric (cosine, pearson, spearman, etc.)\n",
    "    #_calculate_user_similarity\n",
    "    \n",
    "    #switches between equation 2.6 and 2.7 in the paper\n",
    "    #_normalize_to_z_scores\n",
    "    \n",
    "    #the paper suggests a dampening threshhold to keep users from sparse reviews getting rated as overly similar\n",
    "    #_pearson_threshold\n",
    "    \n",
    "    #how many nearest neighbors to look at when computing rating predictions\n",
    "    #_N_similar\n",
    "        \n",
    "    def __init__(self, similarity_type = 'pearson', normalize_to_z_scores=False, pearson_threshold=50,N_similar=20):\n",
    "        self._normalize_to_z_scores = normalize_to_z_scores\n",
    "        self._pearson_threshold = pearson_threshold\n",
    "        self._N_similar = N_similar\n",
    "        if similarity_type=='cosine':\n",
    "            self._calculate_user_similarity = self._cosine_similarity\n",
    "        else: self._calculate_user_similarity = self._pearson_r_similarity_vectorized\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        self._calculate_ratings_matrix(X,y)\n",
    "        self._calculate_user_similarity_matrix_s_vector()\n",
    "    \n",
    "    def _calculate_ratings_matrix(self, X,y):\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        \n",
    "        #preprocessing to make user similarities easier to calculate\n",
    "        self._user_average_rating = self._R.mean(axis=1)\n",
    "        self._user_standard_deviation = self._R.std(axis=1)\n",
    "        \n",
    "    def _calculate_user_similarity_matrix_s_vector(self):\n",
    "        #initialize our similarity matrix _S, and our temp numpy matrix we'll be using while calculating.\n",
    "        self._S = pd.DataFrame(index=self._R.index, columns = self._R.index.rename('User_Prime_ID'), data=0.0)\n",
    "        temp = np.full(self._S.shape,np.nan)\n",
    "        \n",
    "        #We have a user x user matrix of similarity values, but we don't need to do the main diagonal (user1 x user1\n",
    "        #will always have 1.0) and since the top and bottom diagonals are identical (since user1xuser2 = user2xuser1)\n",
    "        #we only bother calculating along the upper triangle. We go row by row, the row sizes decrease as we go.\n",
    "        for index,user1 in enumerate(self._R.index[:-1]):\n",
    "            user2s = self._R.index[index+1:].copy()\n",
    "            temp[index,index+1:] = self._calculate_user_similarity(user1,index,user2s)\n",
    "            \n",
    "        #now that we have the upper triangle values, all we have to do is mirror it to the bottom and we're done.\n",
    "        i_lower = np.tril_indices(temp.shape[0], -1)\n",
    "        temp[i_lower] = temp.T[i_lower] \n",
    "        #turn our numpy temp matrix back into a dataframe.\n",
    "        self._S = pd.DataFrame(temp, columns=self._S.columns, index=self._S.index)\n",
    "            \n",
    "    def _pearson_r_similarity_vectorized(self,user1,user1_index,user2s):\n",
    "        \"\"\"Vectorized implementation of the user x user algorithm. User1 is a single value, index is where user1 appears\n",
    "        in the list, and user2s is a vector of all the users that follow User1.\"\"\"\n",
    "        #get the average for user 1, and a vector of averages for all the other users.\n",
    "        user1_average = self._user_average_rating[user1]\n",
    "        user2_averages = self._user_average_rating[user1_index+1:]\n",
    "        \n",
    "        #find where user1 and user2s have reviewed items. (left half is a bool vector, right is a bool matrix).\n",
    "        #End matrix has each row as a boolean vector showing which items both user1 and the user2 for that row reviewed  \n",
    "        #We're reversing since we want False where both users reviewed the same item, and True elsewhere.\n",
    "        mask = ~(self._R.iloc[user1_index].notnull().as_matrix() & self._R.iloc[user1_index+1:].notnull().as_matrix())\n",
    "\n",
    "        #Turns out working directly with numpy matrixes is faster, so that's what I do from here on out.\n",
    "        #First, null out any item reviews for user2s where user1 didn't have a review.\n",
    "        user2_ratings = self._R.iloc[user1_index+1:].copy().as_matrix()\n",
    "        user2_ratings[mask] = np.NaN\n",
    "        \n",
    "        #now we get a matrix of user1 reviews. Each row corresponds to one of the users in user2s, with all reviews\n",
    "        #nulled except for items both user1 and the user in that row of user2s reviewed.\n",
    "        user1_ratings = np.full(user2_ratings.shape,np.NaN)\n",
    "        user1_base_ratings = self._R.iloc[user1_index].copy().as_matrix()\n",
    "        for i in range(user1_ratings.shape[0]):\n",
    "            user1_ratings[i] = user1_base_ratings\n",
    "            user1_ratings[i, mask[i]] = np.NaN\n",
    "            \n",
    "        #normalize by mean. Turns out subtracting a column vector from a matrix is fussy in numpy.\n",
    "        user1_ratings -= user1_average\n",
    "        user2_ratings = np.subtract(user2_ratings, user2_averages.values.reshape(-1,1))\n",
    "        \n",
    "        #now that we have our normalized reviews, for computational convenience I'm turning NaNs to 0s.\n",
    "        nan_mask = np.isnan(user1_ratings)\n",
    "        user1_ratings[nan_mask] = 0.0\n",
    "        user2_ratings[nan_mask] = 0.0\n",
    "        \n",
    "        #to pevent overly high similarities between users with few reviews in common, a dampening factor of\n",
    "        #min(N/50,1) is applied, where N is the number of items both have reviewed.\n",
    "        num_items = np.sum(~nan_mask,axis=1)\n",
    "        dampening = (num_items/self._pearson_threshold).clip(0,1)\n",
    "        \n",
    "        #pearsonr is cov(1,2)/sqrt(Var(1)*Var(2)). This is just a vectorized implementation, doing row-wise dot \n",
    "        #products between two vectors.\n",
    "        variance1 = (user1_ratings * user1_ratings).sum(axis=1)\n",
    "        variance2 = (user2_ratings * user2_ratings).sum(axis=1)\n",
    "        denom = np.sqrt(variance1*variance2)\n",
    "        covariance = (user1_ratings * user2_ratings).sum(axis=1)\n",
    "\n",
    "        #catch any divide by 0 errors. Any user2s with 0 variance will produce a NaN.\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            ret = (dampening*covariance)/denom\n",
    "            ret[np.isnan(ret)] = 0.0\n",
    "            \n",
    "        return ret\n",
    "        \n",
    "    def _cosine_similarity(self):\n",
    "        pass\n",
    "    \n",
    "    def _find_items_two_users_both_reviewed(self, user1,user2):\n",
    "        return self._items_reviewed[user1].intersection(self._items_reviewed[user2])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"In this vectorized implementation, I assume we're getting enough test values to be worth predicting all\n",
    "        game reviews for each user at once instead of skipping around. For the elite set, there's dozens per user.\n",
    "        For a test set with only one gameID per UserID, this implementation will likely be slower. Worth testing.\"\"\"\n",
    "        output = pd.concat([X,pd.DataFrame(data=np.ones(X.shape[0]),columns=['rating'],index=X.index)],axis=1)\n",
    "        predict_scratch = output.pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "\n",
    "        X.groupby('UserID').apply(self.predict_by_user_vector,predict_scratch)\n",
    "        \n",
    "        #TODO predict_scratch needs to be unwrapped back into its return form. \n",
    "        \n",
    "\n",
    "    def predict_by_user_vector(self, row, predict_scratch):\n",
    "        user = row.iloc[0,0]\n",
    "        \n",
    "        #pd.DataFrame.apply runs the first group twice to see if it can optimize. If it's already ran on the current\n",
    "        #user (e.g, the second iteration of the loop) then skip.\n",
    "        if predict_scratch.loc[user,row.gameID.iloc[0]] != 1.0:\n",
    "            return\n",
    "        \n",
    "        user_average = self._user_average_rating[user]\n",
    "        \n",
    "        #Users with 0 standard deviation should automatically predict their average for any game. This make intuitive\n",
    "        #sense, but it also breaks my code if it's left to run with this edge case.\n",
    "        if self._user_standard_deviation[user] == 0.0:\n",
    "            predict_scratch.loc[user,row.gameID] = user_average\n",
    "            return\n",
    "        \n",
    "        N = self._N_similar\n",
    "            \n",
    "        #these two matrix each have one row per gameID. Columns are similarity values for each similar user,\n",
    "        #and mean normalized ratings each similar user had for that row's game.\n",
    "        similarity_matrix = np.full((row.gameID.size,N),np.NaN)\n",
    "        norm_ratings_matrix = np.full((row.gameID.size,N),np.NaN)\n",
    "\n",
    "        #matrix of masks to get users that have reviewed a given game.\n",
    "        who_reviewed_which_games = self._R.loc[:,row.gameID].notnull().as_matrix().T\n",
    "        \n",
    "        \n",
    "        #OPTIMIZATION IDEA: \n",
    "        #with numpy, you can case a boolean matrix against a single column (or row) array and get a matrix back. \n",
    "        #wtih a little tweaking, most of this inner for loop could be taken out of the loop, since similarity_matrix\n",
    "        #and norm matrix are both just numpy matrixes anyway.\n",
    "        for i in range(row.shape[0]):\n",
    "            #first I find the N most similar users that reviewed this gameID.\n",
    "            similarity = self._S.loc[user,who_reviewed_which_games[i]].nlargest(N)\n",
    "\n",
    "            #since it's much faster to do a look by boolean mask instead of by index, I get the top 20 users as\n",
    "            #a mask instead of a list of values. That'll speed up lookups later in this loop. \n",
    "            mask = self._S.loc[user,:].isin(similarity.values)\n",
    "            similarity = self._S.loc[user,mask]\n",
    "\n",
    "            similarity_matrix[i,:] = similarity.values\n",
    "\n",
    "            #calculate the row in the ratings matrix for this iteration's gameID\n",
    "            user_prime_averages = self._user_average_rating[mask].values\n",
    "            user_prime_ratings = self._R.loc[mask,row.iloc[i].gameID].values\n",
    "            norm_ratings_matrix[i,:] = user_prime_ratings - user_prime_averages\n",
    "\n",
    "        estimated_user_reviews = user_average + (similarity_matrix * norm_ratings_matrix).sum(axis=1)/N\n",
    "        predict_scratch.loc[user,row.gameID] = estimated_user_reviews\n",
    "  \n",
    "\n",
    "    #Below functions are for establishing a baseline with simple enough algorithms that I'm confident in it's efficacy.\n",
    "    def naive_person_r_calc(self,u1,u2):\n",
    "        u1 = self._R.loc[user1].copy()\n",
    "        u2 = self._R.loc[user2].copy()\n",
    "\n",
    "        u1mean = u1.mean()\n",
    "        u2mean = u2.mean()\n",
    "\n",
    "        i1 = set(u1.dropna().index.tolist())\n",
    "        i2 = set(u2.dropna().index.tolist())\n",
    "        shared = i1.intersection(i2)\n",
    "\n",
    "        u1 = u1.loc[shared].sort_index()\n",
    "        u2 = u2.loc[shared].sort_index()\n",
    "\n",
    "        u1 -= u1mean\n",
    "        u2 -= u2mean\n",
    "\n",
    "        return np.dot(u1,u2)/np.sqrt(np.dot(u1,u1)*(np.dot(u2,u2)))\n",
    "        \n",
    "    #simple algorithm for establishing a baseline to use against the more complex vectorized implementation.\n",
    "    def _naive_single_predict_function(self, user, game):\n",
    "        user_mean = self._user_average_rating[user]\n",
    "        N = self._N_similar\n",
    "    \n",
    "        #nearest users IDs are the index of this series, s(u,u') is the values. It's filtered so only users\n",
    "        #who have also rated the game in question are considered. \n",
    "        N_nearest_similar = self._S[user][self._R[game].notnull()].nlargest(N)\n",
    "        \n",
    "        #display(N_nearest_similar.index)\n",
    "    \n",
    "        #vectors for most similar user information\n",
    "        similar_users_means = self._user_average_rating[N_nearest_similar.index].values\n",
    "        similar_users_item_ratings = self._R.loc[N_nearest_similar.index, game].values\n",
    "    \n",
    "        user_std = 1.0\n",
    "        similar_users_stds = np.full(N,1.0)\n",
    "        if(self._normalize_to_z_scores):\n",
    "            user_std = self._user_standard_deviation[user]\n",
    "            similar_users_stds = self._user_standard_deviation[N_nearest_similar.index].values\n",
    "    \n",
    "        similar_users_z_values = (similar_users_item_ratings-similar_users_means)/similar_users_stds\n",
    "        prediction = user_mean + ((user_std/N) * np.dot(N_nearest_similar.values,similar_users_z_values))\n",
    "    \n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "def test_user_user_similarity_matrix_vector_function():\n",
    "    predictor = U_U_predictor()\n",
    "    predictor._calculate_ratings_matrix(train_X,train_y)\n",
    "    R = predictor._R\n",
    "    predictor.fit(train_X,train_y)\n",
    "    assert R.equals(predictor._R),\"ratings matrix was changed by a function that wasn't supposed to alter it.\"\n",
    "    \n",
    "    S = pd.read_pickle('user_S')\n",
    "    #making sure that whatever method I'm using to calculate S, that it roughly equals my established baseline using\n",
    "    #a naive calculation that I picked. \n",
    "    assert S.size==np.count_nonzero(np.isclose(S, predictor._S, rtol=1e-07, atol=1e-010, equal_nan=True)),\"Similarity matrix was incorrectly calculated with PearsonR.\"\n",
    "\n",
    "\n",
    "def test_predict_function():\n",
    "    for index,row in test_X.iloc[:10].iterrows():\n",
    "        naive_prediction = predictor._naive_single_predict_function(row.UserID,row.gameID)\n",
    "\n",
    "test_user_user_similarity_matrix_vector_function()\n",
    "test_predict_function()\n",
    "\n",
    "#60s\n",
    "\n",
    "#predictor.predict(test_X)\n",
    "\n",
    "#similarity_matrix = np.full((games.size,N),np.NaN)\n",
    "\n",
    "#test_X.reset_index(drop=True)\n",
    "#list(test_X.set_index('gameID').groupby('UserID'))[0]\n",
    "    \n",
    "%lprun -f U_U_predictor.predict_by_user_vector predictor.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 904 ms, sys: 0 ns, total: 904 ms\n",
      "Wall time: 913 ms\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "#was 189 seconds\n",
    "#was 97 seconds. \n",
    "#was 49 seconds\n",
    "#calling it good at .8 seconds\n",
    "\n",
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "%lprun -f predictor.fit predictor.fit(train_X,train_y)\n",
    "#%time predictor.fit(train_X,train_y)\n",
    "\n",
    "#predictions = predictor.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Error checking\n",
    "\n",
    "Now that I've gotten some models built out, I can use Sklearn's framework to check out different prediction systems, compare RMSE, and see what kind of model works the best with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32964534833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#predictor = Base_Predictor()\n",
    "#train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "#predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d75559098933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=10)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43703165214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30633111229\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=5)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31054160406\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=3)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30322536673\n"
     ]
    }
   ],
   "source": [
    "predictor = Base_Predictor()\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
